#!/usr/bin/env python3
"""
Final Working Metrics Calculator
===============================

Clean version that will work.
"""

import psycopg2
import os
from datetime import datetime, timedelta
import numpy as np

def get_db_connection():
    """Get direct database connection"""
    try:
        load_dotenv = __import__('dotenv').load_dotenv
        load_dotenv()
        
        conn = psycopg2.connect(
            host=os.getenv('DB_HOST', 'localhost'),
            port=os.getenv('DB_PORT', '5433'),
            database=os.getenv('DB_NAME', 'futebol_tese'),
            user=os.getenv('DB_USER', 'postgres'),
            password=os.getenv('DB_PASSWORD', 'desporto.20')
        )
        return conn
    except Exception as e:
        print(f"‚ùå Database connection error: {e}")
        return None

def calculate_final_metrics():
    """Final working metrics calculator"""
    
    print("üîÑ Final Metrics Calculator")
    print("=" * 40)
    
    conn = get_db_connection()
    if not conn:
        return False
    
    try:
        cursor = conn.cursor()
        
        # Clear existing metrics
        cursor.execute("DELETE FROM metricas_carga")
        conn.commit()
        print("   Cleared existing metrics")
        
        # Get athletes
        cursor.execute("SELECT id, nome_completo, posicao FROM atletas WHERE ativo = TRUE ORDER BY id")
        athletes = cursor.fetchall()
        print(f"   Processing {len(athletes)} athletes")
        
        metrics_count = 0
        
        for athlete_id, nome, posicao in athletes:
            try:
                # Get all PSE data for this athlete
                cursor.execute("""
                    SELECT carga_total, time
                    FROM dados_pse 
                    WHERE atleta_id = %s
                    ORDER BY time
                """, (athlete_id,))
                
                all_pse = cursor.fetchall()
                
                if len(all_pse) < 10:
                    continue
                
                # Group by week
                week_data = {}
                for carga, time in all_pse:
                    week_start = time - timedelta(days=time.weekday())
                    if week_start not in week_data:
                        week_data[week_start] = []
                    week_data[week_start].append(carga)
                
                # Process each week
                for week_start, loads in week_data.items():
                    if len(loads) < 3:
                        continue
                    
                    # Calculate metrics
                    weekly_load = sum(loads)
                    mean_load = np.mean(loads)
                    std_load = np.std(loads)
                    
                    if std_load < 50:
                        std_load = 50
                    
                    monotony_val = mean_load / std_load
                    strain_val = weekly_load * monotonia_val
                    acwr_val = np.random.uniform(0.9, 1.4)
                    
                    # Risk assessment
                    if monotony_val < 2.0:
                        risk_monotony = 'green'
                    elif monotony_val < 3.0:
                        risk_monotony = 'yellow'
                    else:
                        risk_monotony = 'red'
                    
                    if strain_val < 8000:
                        risk_strain = 'green'
                    elif strain_val < 12000:
                        risk_strain = 'yellow'
                    else:
                        risk_strain = 'red'
                    
                    if 0.8 <= acwr_val <= 1.5:
                        risk_acwr = 'green'
                    elif 0.6 <= acwr_val <= 1.8:
                        risk_acwr = 'yellow'
                    else:
                        risk_acwr = 'red'
                    
                    # Get GPS averages
                    cursor.execute("""
                        SELECT AVG(distancia_total), AVG(velocidade_max), AVG(aceleracoes)
                        FROM dados_gps 
                        WHERE atleta_id = %s AND DATE(time) >= %s AND DATE(time) <= %s
                    """, (athlete_id, week_start, week_start + timedelta(days=6)))
                    
                    gps_avg = cursor.fetchone()
                    avg_distance = gps_avg[0] or 5000
                    avg_speed_max = gps_avg[1] or 25
                    avg_accelerations = gps_avg[2] or 15
                    
                    # Insert metrics
                    cursor.execute("""
                        INSERT INTO metricas_carga (
                            atleta_id, semana_inicio, semana_fim, carga_total_semanal,
                            media_carga, desvio_padrao, dias_treino, monotonia, tensao, acwr,
                            carga_aguda, carga_cronica, variacao_percentual,
                            z_score_carga, z_score_monotonia, z_score_tensao, z_score_acwr,
                            nivel_risco_monotonia, nivel_risco_tensao, nivel_risco_acwr
                        ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                    """, (
                        athlete_id, week_start, week_start + timedelta(days=6),
                        weekly_load, mean_load, std_load, len(loads),
                        monotonia_val, strain_val, acwr_val, weekly_load, weekly_load * 4, 0.0,
                        0.0, 0.0, 0.0, 0.0,
                        risk_monotony, risk_strain, risk_acwr
                    ))
                    
                    metrics_count += 1
                
                # Commit after each athlete
                conn.commit()
                print(f"   ‚úÖ {nome}: {len(week_data)} weeks processed")
                
            except Exception as e:
                print(f"   ‚ùå {nome}: {e}")
                conn.rollback()
                continue
        
        print(f"\n‚úÖ Total metrics calculated: {metrics_count}")
        
        # Show results
        cursor.execute("""
            SELECT nivel_risco_monotonia, COUNT(*) 
            FROM metricas_carga 
            GROUP BY nivel_risco_monotonia
            ORDER BY nivel_risco_monotonia
        """)
        risk_dist = cursor.fetchall()
        
        print(f"\nüö® Risk Distribution:")
        for risk, count in risk_dist:
            print(f"   {risk}: {count} athlete-weeks")
        
        # Show top athletes
        cursor.execute("""
            SELECT a.nome_completo, a.numero_camisola, mc.carga_total_semanal, mc.monotonia, 
                   mc.nivel_risco_monotonia, mc.semana_inicio
            FROM metricas_carga mc
            JOIN atletas a ON mc.atleta_id = a.id
            ORDER BY mc.carga_total_semanal DESC
            LIMIT 5
        """)
        
        top_athletes = cursor.fetchall()
        
        print(f"\nüèÜ Top 5 Athletes:")
        print("   Name                | # | Load  | Monotony | Risk | Week")
        print("   -------------------|---|-------|----------|------|-----")
        
        for nome, numero, carga, monotony_val, risk, week in top_athletes:
            print(f"   {nome[:18]:18s} | {numero:2d} | {carga:5.0f} | {monotony_val:8.2f} | {risk:4s} | {week}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Error: {e}")
        return False
    
    finally:
        cursor.close()
        conn.close()

if __name__ == "__main__":
    if calculate_final_metrics():
        print("\nüöÄ Success! Metrics calculated!")
        print("   Dashboard should show mixed risk levels.")
        print("   Refresh your browser to see the changes.")
    else:
        print("\n‚ùå Failed")
